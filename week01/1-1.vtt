WEBVTT

1
00:00:00.000 --> 00:00:09.423
[MUSIC]

2
00:00:09.423 --> 00:00:12.718
In this lecture we'll talk about three
different ways in which you can draw

3
00:00:12.718 --> 00:00:15.070
statistical inferences from your data.

4
00:00:15.070 --> 00:00:17.650
We can see that there are three
main questions that you can

5
00:00:17.650 --> 00:00:21.120
ask which are all related to
different statistical approaches.

6
00:00:21.120 --> 00:00:24.732
So let's take a look at
each of these in-turn.

7
00:00:24.732 --> 00:00:25.747
Now in statistics,

8
00:00:25.747 --> 00:00:29.930
we'll see that there's basically one
truth that we all try to figure out.

9
00:00:29.930 --> 00:00:34.210
But the paths toward this truth, there
are many different ways to try to do this.

10
00:00:34.210 --> 00:00:38.410
One useful metaphor that I think can
help you think about these differences

11
00:00:38.410 --> 00:00:40.960
is if we look at Hinduism.

12
00:00:42.200 --> 00:00:46.120
The Karma yoga, the Jnana yoga,
and the Bhakti yoga.

13
00:00:46.120 --> 00:00:50.542
Now if you see what the Hinduist
book [UNKNOWN says about this

14
00:00:50.542 --> 00:00:56.040
there's basically a path of action, a path
of devotion and a path of knowledge.

15
00:00:56.040 --> 00:01:00.400
And I think there's a nice relation
to make between these three paths and

16
00:01:00.400 --> 00:01:03.930
three questions that you can
ask if you do statistics.

17
00:01:03.930 --> 00:01:07.590
Now, Royall talks about these three
different questions that one might ask.

18
00:01:07.590 --> 00:01:12.140
And he differentiates between what
should I do, what should I believe and

19
00:01:12.140 --> 00:01:14.180
what's the relative evidence?

20
00:01:14.180 --> 00:01:17.400
And we see that these are three
different statistical approaches

21
00:01:17.400 --> 00:01:19.310
that we can use to draw
inferences from data.

22
00:01:21.030 --> 00:01:23.560
The first is the path of action.

23
00:01:23.560 --> 00:01:28.380
The path of action uses rules to
govern our behavior such that,

24
00:01:28.380 --> 00:01:31.930
in the long run, we won't make
a fool out of ourselves too often.

25
00:01:32.960 --> 00:01:37.910
Now this approach uses p-values and
alpha levels to either make a decision to

26
00:01:37.910 --> 00:01:42.880
reject the null hypothesis, or to accept
the null hypothesis, or if you want

27
00:01:42.880 --> 00:01:46.900
to remain in doubt about whether
the alternative hypothesis is true or not.

28
00:01:48.790 --> 00:01:52.520
This is a rule to govern our
behavior in the long run.

29
00:01:52.520 --> 00:01:56.198
It's important to keep in mind that
this doesn't tell you anything about one

30
00:01:56.198 --> 00:01:58.077
single test that you're performing.

31
00:01:58.077 --> 00:02:02.150
So any current test might
be either true or false.

32
00:02:02.150 --> 00:02:04.470
We don't know but
what we know is that in the long run,

33
00:02:04.470 --> 00:02:07.480
there's a certain percentage of
the time that will be correct.

34
00:02:07.480 --> 00:02:09.670
So this is the main goal
of the path of action.

35
00:02:09.670 --> 00:02:11.420
Making decisions about what you should do.

36
00:02:13.080 --> 00:02:16.650
The path of knowledge, the second way,
focuses on likelihoods.

37
00:02:16.650 --> 00:02:19.690
And it tries to answer the question
what the likelihood is

38
00:02:19.690 --> 00:02:22.650
of different hypotheses given
the data that you have collected.

39
00:02:23.790 --> 00:02:28.330
Let's take a look at the situation
where you flip a coin ten times.

40
00:02:28.330 --> 00:02:31.480
This is an old Dutch
from when I was young.

41
00:02:31.480 --> 00:02:35.240
And we see that there are six heads and
four tales.

42
00:02:35.240 --> 00:02:39.160
So if you flip this, if you flip a coin
ten times and this is the data that you

43
00:02:39.160 --> 00:02:44.100
have observed, you can ask yourself
the question, is this coin biased or not?

44
00:02:44.100 --> 00:02:47.230
So what is the likelihood
that this is a fair where

45
00:02:47.230 --> 00:02:49.960
every option comes up 50% of the time?

46
00:02:49.960 --> 00:02:52.099
Or what's the likelihood
that this is a biased coin?

47
00:02:53.140 --> 00:02:57.480
Now we can plot the likelihood function
given the data that we have observed.

48
00:02:57.480 --> 00:03:00.530
Let's take a look at
the likelihood function.

49
00:03:00.530 --> 00:03:03.930
So this curves tells us all
the likelihood of different

50
00:03:03.930 --> 00:03:06.580
hypotheses given the data that we have.

51
00:03:06.580 --> 00:03:09.600
Now we've observed six heads,
so you can see that this,

52
00:03:09.600 --> 00:03:13.830
according to the likelihood function,
is the most likely possibility, but

53
00:03:13.830 --> 00:03:16.350
we can also calculate
the likelihood ratio.

54
00:03:16.350 --> 00:03:20.320
How much more likely is the data
that we have given a fair coin?

55
00:03:20.320 --> 00:03:22.578
And we see that this is
not very impressive.

56
00:03:22.578 --> 00:03:24.810
The likelihood ratio's supposed to be 1,

57
00:03:24.810 --> 00:03:29.680
if there's no difference between different
hypothesis, and this is pretty close to 1.

58
00:03:29.680 --> 00:03:32.690
Later on in the course, we'll talk about
how you can really calculate these things.

59
00:03:34.640 --> 00:03:37.680
The last option is the path of belief.

60
00:03:37.680 --> 00:03:41.870
Now we have flipped a coin ten times, and
we saw that it came up heads six times.

61
00:03:43.000 --> 00:03:48.060
Now if you see this, do you really believe
that the coin in the long run will come up

62
00:03:48.060 --> 00:03:49.390
heads 60% of the time?

63
00:03:50.910 --> 00:03:52.990
Now that seems rather unlikely.

64
00:03:52.990 --> 00:03:55.760
You have previous beliefs about coins, and

65
00:03:55.760 --> 00:03:59.280
you have a very strong belief
that most coins are fair.

66
00:03:59.280 --> 00:04:02.260
So in the long run you might say,
well, I've observed this.

67
00:04:02.260 --> 00:04:04.300
This one time there were six heads, but

68
00:04:04.300 --> 00:04:08.300
I don't really believe that this is what I
will see if I continue flipping the coin.

69
00:04:08.300 --> 00:04:12.480
I think, still, that 50% probability
of heads is what's going to happen

70
00:04:12.480 --> 00:04:15.460
if I do this over and over again.

71
00:04:15.460 --> 00:04:20.560
So you see that in this case, the data
did not really change your prior beliefs.

72
00:04:20.560 --> 00:04:23.400
And this path is known
as Bayesian statistics,

73
00:04:23.400 --> 00:04:27.060
which allows you to express evidence
in terms of the degrees of belief.

74
00:04:27.060 --> 00:04:31.168
So how much do you believe
in a certain hypothesis?

75
00:04:31.168 --> 00:04:34.970
So these three different paths, the path
of action, the path of devotion, and

76
00:04:34.970 --> 00:04:36.460
the path of knowledge.

77
00:04:36.460 --> 00:04:41.180
We can sort of make a relationship to
Neyman-Pearson statistics, which is

78
00:04:41.180 --> 00:04:45.390
the path of action using alpha levels to
decide between the null hypothesis and

79
00:04:45.390 --> 00:04:47.150
the alternate hypothesis.

80
00:04:47.150 --> 00:04:51.448
Bayesian statistics, where we talk about
the degree of belief in hypothesis.

81
00:04:51.448 --> 00:04:55.509
And likelihoods which tell us something
about relative evidence between different

82
00:04:55.509 --> 00:04:56.200
hypothesis.

83
00:04:58.090 --> 00:05:02.580
Now, in the history of statistics, we see
that there's a lot of discussion going on

84
00:05:02.580 --> 00:05:04.390
between different sides in this debate.

85
00:05:04.390 --> 00:05:08.470
And if you want to know how nasty science
can get, then I invite you to take a look

86
00:05:08.470 --> 00:05:11.610
at the discussion in the scientific
literature between this person on

87
00:05:11.610 --> 00:05:14.850
the left, Jerzey Neyman, and
the person on the right, Ronald Fisher.

88
00:05:15.970 --> 00:05:18.290
Now, Jerzey Neyman is
about the path of action.

89
00:05:18.290 --> 00:05:21.505
And Ronald Fisher uses p-values
in a slightly different way.

90
00:05:21.505 --> 00:05:23.780
P-values as a measure of evidence.

91
00:05:23.780 --> 00:05:28.520
Now, Ronald Fisher is a genius, one of
the few geniuses that we have in science.

92
00:05:28.520 --> 00:05:31.120
He's not only a godfather of statistics,

93
00:05:31.120 --> 00:05:34.542
he worked a lot on introducing
analysis of variance, for example.

94
00:05:34.542 --> 00:05:38.360
But he's also a very respected
scholar in the field of biology,

95
00:05:38.360 --> 00:05:40.660
where he did groundbreaking work as well.

96
00:05:40.660 --> 00:05:44.550
So this is no doubt a very smart
individual, but there's a lot of debate

97
00:05:44.550 --> 00:05:48.780
about the way that he uses p-values
to draw inferences from your data.

98
00:05:49.890 --> 00:05:53.670
So if there's a discussion between these
two individuals, you can say, well,

99
00:05:53.670 --> 00:05:57.950
the Neyman-Pierson approach to inference
is definitely the best way, the most

100
00:05:57.950 --> 00:06:02.255
coherent way, to draw inferences from
data using alpha levels and the p-value.

101
00:06:03.500 --> 00:06:07.580
So Neyman would be really happy,
say, haha, after all these years and

102
00:06:07.580 --> 00:06:10.740
this intense discussion that we had,
I've won.

103
00:06:10.740 --> 00:06:14.670
My way of doing statistics is
the only logical approach to draw

104
00:06:14.670 --> 00:06:15.830
statistical inferences.

105
00:06:15.830 --> 00:06:19.150
On the other hand,
Fisher might not be too sad.

106
00:06:19.150 --> 00:06:21.050
He might say, forget it.

107
00:06:21.050 --> 00:06:23.790
No one knows who you are,
which is in general true.

108
00:06:23.790 --> 00:06:28.490
I think not a lot of people have heard of
the Neyman-Pearson approach of statistics.

109
00:06:28.490 --> 00:06:31.830
And he would be pretty happy
that everybody uses p-values in,

110
00:06:31.830 --> 00:06:36.340
well, arguably, not the optimal way,
but at least the way that he proposed.

111
00:06:37.770 --> 00:06:41.020
And, well,
he gets a lot of respect for this.

112
00:06:41.020 --> 00:06:44.220
You might not know this, but
the F-distribution, the F-value

113
00:06:44.220 --> 00:06:47.950
that you calculate in an ANOVA, is
actually named after Fisher in his honor.

114
00:06:49.300 --> 00:06:52.040
All right, so
these two sides are debating, but

115
00:06:52.040 --> 00:06:55.560
now we see that Bayesian statistics
is on the rise in recent years.

116
00:06:55.560 --> 00:06:58.484
This is Reverend Thomas Bayes,
or actually probably not.

117
00:06:58.484 --> 00:07:01.630
This is a picture that's
circulating that might be him, but

118
00:07:01.630 --> 00:07:04.340
it's doubtful that it's actually him.

119
00:07:04.340 --> 00:07:07.770
Nevertheless, we'll use it in this course
to illustrate the Bayesian perspective.

120
00:07:08.890 --> 00:07:11.410
And he would say,
gentleman, Quit fighting.

121
00:07:11.410 --> 00:07:15.180
Who cares about these frequentist
approaches to statistics that you

122
00:07:15.180 --> 00:07:16.110
think are important.

123
00:07:16.110 --> 00:07:19.430
Because everybody in the future will
use Bayesian statistics anyway.

124
00:07:20.680 --> 00:07:22.450
We can see whether that's true or not.

125
00:07:22.450 --> 00:07:24.447
And maybe Neyman would respond, well,

126
00:07:24.447 --> 00:07:27.863
I don't have a really high prior
that this is really going to happen.

127
00:07:27.863 --> 00:07:29.363
Which of course, is a sly joke,

128
00:07:29.363 --> 00:07:33.470
because he's using prior information
to draw an inference in this case.

129
00:07:33.470 --> 00:07:36.730
And you see that when there's a discussion
between Bayesian statistics and

130
00:07:36.730 --> 00:07:41.130
frequentist statistics, all of sudden, of
course, these two become perfect friends.

131
00:07:41.130 --> 00:07:43.790
They say, of course, very good joke.

132
00:07:43.790 --> 00:07:47.809
And they will be in agreement
about the way to do statistics.

133
00:07:49.210 --> 00:07:52.330
Now the third approach is
the likelihood approach.

134
00:07:52.330 --> 00:07:57.620
It's not very popular at the moment, but
likelihoods underlay Bayesian statistics.

135
00:07:57.620 --> 00:08:01.145
And the difference between likelihoods and
Bayesian statistics,

136
00:08:01.145 --> 00:08:05.223
is that likelihoods do use the relative
evidence that's present in the data,

137
00:08:05.223 --> 00:08:06.917
as Bayesian statisticians do.

138
00:08:06.917 --> 00:08:10.840
But it doesn't rely on
this subjective prior.

139
00:08:10.840 --> 00:08:14.060
One of the proponents of this
approach is Rich Royall.

140
00:08:14.060 --> 00:08:18.190
And he might say something that nobody
really cares about your subjective opinion

141
00:08:18.190 --> 00:08:20.350
when you draw inferences from data.

142
00:08:20.350 --> 00:08:25.450
So you should ignore this subjective
prior and only rely on the likelihood.

143
00:08:25.450 --> 00:08:29.630
To which Thomas Bayes might say,
come on, don't be such a nuisance.

144
00:08:29.630 --> 00:08:32.260
Nobody even knows what
likelihood paradigm is.

145
00:08:32.260 --> 00:08:35.230
At this moment this might be true but
we'll see you can use it for

146
00:08:35.230 --> 00:08:38.270
certain useful things later
on in these lectures.

147
00:08:39.590 --> 00:08:42.466
Now, it's very important to
realize that in this debate,

148
00:08:42.466 --> 00:08:45.630
which sometimes feels a little
bit like Microsoft versus Apple,

149
00:08:45.630 --> 00:08:47.943
there's always this
clash between two sides.

150
00:08:47.943 --> 00:08:52.850
And people will start to argue vehemently
between these two different approaches.

151
00:08:52.850 --> 00:08:57.050
For you, it's very important that you
can use whatever answers your question.

152
00:08:57.050 --> 00:08:58.370
And that's really the main point.

153
00:08:58.370 --> 00:08:59.480
It's not either, or.

154
00:08:59.480 --> 00:09:01.850
You can even combine these
approaches if you want to.

155
00:09:03.680 --> 00:09:07.845
So the important take-home message here is
that there are three different approaches

156
00:09:07.845 --> 00:09:10.500
in how you can draw
inferences from your data.

157
00:09:10.500 --> 00:09:13.687
These all answer a question
you might be interested in.

158
00:09:13.687 --> 00:09:16.907
And the main thing is that you
realize that there are all

159
00:09:16.907 --> 00:09:18.867
these different approaches, so

160
00:09:18.867 --> 00:09:22.865
you can ask the question that will
give you the answer that you want.

161
00:09:22.865 --> 00:09:25.959
[MUSIC]