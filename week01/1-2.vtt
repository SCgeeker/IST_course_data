WEBVTT

1
00:00:00.000 --> 00:00:09.575
[MUSIC]

2
00:00:09.575 --> 00:00:12.311
If you read articles in
the scientific literature,

3
00:00:12.311 --> 00:00:17.405
you'll often see people report P-values
when they report statistical tests.

4
00:00:17.405 --> 00:00:21.660
P-values are widely used, and it's
important to understand what they mean.

5
00:00:21.660 --> 00:00:26.290
They're also widely criticized, because
people often misinterpret p-values.

6
00:00:26.290 --> 00:00:29.430
So in this lecture, the goal is
to understand what they mean and

7
00:00:29.430 --> 00:00:30.830
how to correctly interpret them.

8
00:00:32.090 --> 00:00:36.120
When we talk about p-values, the first
question we should ask ourselves is

9
00:00:36.120 --> 00:00:39.610
why are they so
popular in scientific articles?

10
00:00:40.610 --> 00:00:45.060
Well, there's a reason for this, and
Benjamini expresses it quite nicely.

11
00:00:45.060 --> 00:00:50.000
He says in some sense it offers
a first line of defense against

12
00:00:50.000 --> 00:00:55.030
being fooled by randomness,
separating the signal from the noise.

13
00:00:55.030 --> 00:00:57.670
So, this is what the p-values
allow you to do.

14
00:00:57.670 --> 00:00:59.550
When you interpret your data,

15
00:00:59.550 --> 00:01:05.780
you might be very likely to interpret data
in favor of the hypothesis that you have,

16
00:01:05.780 --> 00:01:09.210
even when the effect might be only
slightly in the right direction.

17
00:01:09.210 --> 00:01:11.120
The risk is that you're fooling yourself.

18
00:01:11.120 --> 00:01:14.830
You might be too likely to declare
that something is going on,

19
00:01:14.830 --> 00:01:18.080
when you're actually looking
at random variation in data.

20
00:01:18.080 --> 00:01:21.315
So, p-values are one way to
prevent you from fooling yourself.

21
00:01:21.315 --> 00:01:29.195
P-values tell you how surprising the data
is, assuming that there is no effect.

22
00:01:29.195 --> 00:01:32.450
And we'll look at all these
aspects in more detail.

23
00:01:32.450 --> 00:01:36.350
What surprising means,
why they're statements about the data, and

24
00:01:36.350 --> 00:01:38.719
why they're built on the idea
that there is no effect.

25
00:01:41.060 --> 00:01:43.630
Now, some people say
that p-values are more

26
00:01:43.630 --> 00:01:48.255
accurately explained as what you use if
you don't know Bayesian statistics yet.

27
00:01:48.255 --> 00:01:52.810
In Bayesian statistics,
people don't use p-values.

28
00:01:52.810 --> 00:01:56.670
And I still remember when I
was doing my own PhD, that I

29
00:01:56.670 --> 00:02:02.010
had this confusion about whether I should
use p-values, or Bayesian statistics.

30
00:02:02.010 --> 00:02:06.070
My understanding was, more or less,
that I realized there was some problem

31
00:02:06.070 --> 00:02:11.040
with using p-values, and Bayesian
statistics might be preferable, but

32
00:02:11.040 --> 00:02:13.310
most people didn't use
Bayesian statistics.

33
00:02:13.310 --> 00:02:17.430
So, it was probably fine to
just continue using p-values.

34
00:02:17.430 --> 00:02:22.150
Now, I think it's fine to use p-values,
but you should interpret them correctly.

35
00:02:22.150 --> 00:02:25.430
So, that's the goal in this lecture,
to prevent this confusion in you,

36
00:02:25.430 --> 00:02:29.270
and to make sure that you use p-values
correctly, if you decide to use them.

37
00:02:31.280 --> 00:02:33.850
Let's start with a practical example.

38
00:02:33.850 --> 00:02:38.420
Let's say you want to to do a study where
you examine the influence of calling

39
00:02:38.420 --> 00:02:39.545
while you are driving.

40
00:02:39.545 --> 00:02:43.620
Does being on the phone when you
are in your car increase the risk of

41
00:02:43.620 --> 00:02:45.530
getting into an accident?

42
00:02:45.530 --> 00:02:50.090
You might design a study where half of
the participants drive around the city

43
00:02:50.090 --> 00:02:54.120
while they're on the phone, and the other
half of the participants drive around, but

44
00:02:54.120 --> 00:02:54.820
they're not on the phone.

45
00:02:55.910 --> 00:02:57.570
You want to see if there's a difference,

46
00:02:57.570 --> 00:03:01.810
maybe in the number of people they hit
while they're driving through the street.

47
00:03:03.120 --> 00:03:06.610
Or maybe your ethical committee
doesn't allow you to do this,

48
00:03:06.610 --> 00:03:10.299
and you're better off using
a driving simulator to study this.

49
00:03:11.440 --> 00:03:15.530
Now, if you have collected your data, you
counted how many people get hit by a car,

50
00:03:15.530 --> 00:03:18.250
either by people who are on
the phone while they're driving or

51
00:03:18.250 --> 00:03:20.310
people who are not on the phone,

52
00:03:20.310 --> 00:03:23.300
then you can look at the difference
between these two conditions.

53
00:03:24.440 --> 00:03:27.420
Now, this difference
is never exactly zero.

54
00:03:27.420 --> 00:03:33.140
There's always some number follow after
the comma that makes a difference.

55
00:03:33.140 --> 00:03:38.290
So, let's say the difference you
observe is 0.11, a mean difference.

56
00:03:38.290 --> 00:03:41.010
Now, how should you interpret
this mean difference?

57
00:03:41.010 --> 00:03:42.980
There are two options.

58
00:03:42.980 --> 00:03:46.995
A, what you are looking at is
probably just random noise.

59
00:03:46.995 --> 00:03:49.760
There's always some random
noise in your data.

60
00:03:49.760 --> 00:03:53.850
Option B, this is probably a real
difference, this is something that

61
00:03:53.850 --> 00:03:59.070
you should take seriously, and at least
examine further in future studies.

62
00:03:59.070 --> 00:04:01.050
So, which of these two is true.

63
00:04:01.050 --> 00:04:04.769
Well, we can use the p-value to
differentiate between these two options.

64
00:04:06.730 --> 00:04:11.370
From the data that we have, we can
calculate means, standard deviations, and

65
00:04:11.370 --> 00:04:13.740
we know the sample size that we have.

66
00:04:13.740 --> 00:04:18.010
We can use these parameters to
calculate a test statistic, and

67
00:04:18.010 --> 00:04:21.260
compare this test statistic
against a distribution.

68
00:04:22.350 --> 00:04:25.350
You can use many different
types of distributions.

69
00:04:25.350 --> 00:04:30.430
If you examine precognition, you might
want to use a paranormal distribution.

70
00:04:30.430 --> 00:04:34.300
But most often,
people just use the normal distribution.

71
00:04:34.300 --> 00:04:38.360
So, this bell shaped graph is
something you might have seen before.

72
00:04:38.360 --> 00:04:41.130
And there's something you
should note here, and

73
00:04:41.130 --> 00:04:44.710
that's that this distribution
is centered on zero.

74
00:04:44.710 --> 00:04:49.930
And when we talk about the p-value
being data that is surprising,

75
00:04:49.930 --> 00:04:54.120
assuming the null is true, the null
hypothesis is true, this is what we mean.

76
00:04:54.120 --> 00:04:56.150
We look at a distribution
centered at zero.

77
00:04:57.270 --> 00:05:01.950
Now, you can see that most of
the data in this case, let's look

78
00:05:01.950 --> 00:05:07.220
at 95% of the data,
will fall between two critical values.

79
00:05:07.220 --> 00:05:13.144
And these critical values, you might
have seen this number, 1.96 and -1.96.

80
00:05:13.144 --> 00:05:17.930
These are critical values if you
want to use an alpha level of 0.05.

81
00:05:17.930 --> 00:05:23.060
If data falls between these two values,
it's not surprising.

82
00:05:23.060 --> 00:05:25.450
Assuming that the null hypothesis is true,

83
00:05:25.450 --> 00:05:28.829
most of the data will fall between
these two critical values.

84
00:05:29.880 --> 00:05:35.020
But sometimes, we might see a data
point that's more extreme than this.

85
00:05:35.020 --> 00:05:37.250
And this is a surprising find.

86
00:05:37.250 --> 00:05:42.080
This is surprising data whenever the mean
difference, or the test statistic that is

87
00:05:42.080 --> 00:05:47.420
computed from this mean difference, is in
one of the two tails of this distribution.

88
00:05:47.420 --> 00:05:51.150
So, whenever we find that data that
falls in these tails, it's surprising.

89
00:05:51.150 --> 00:05:53.220
And we might want to examine it further.

90
00:05:53.220 --> 00:05:56.030
It also means that the p-value's
smaller than 0.05.

91
00:05:56.030 --> 00:06:03.960
The formal definition of a p-value is
the probability of getting the observed,

92
00:06:03.960 --> 00:06:07.920
or more extreme data,
assuming the null hypothesis is true.

93
00:06:09.080 --> 00:06:10.920
Now, I highlighted the word data here.

94
00:06:10.920 --> 00:06:14.560
I think it's important to realize that
we're talking about the probability of

95
00:06:14.560 --> 00:06:15.440
observing data.

96
00:06:16.830 --> 00:06:19.670
A p-value is the probability
that you'll observe some data,

97
00:06:19.670 --> 00:06:23.610
but not the probability of a theory.

98
00:06:23.610 --> 00:06:26.170
This is a very common misunderstanding.

99
00:06:26.170 --> 00:06:28.980
People often want to make a statement
about the probability that

100
00:06:28.980 --> 00:06:30.530
the theory is true.

101
00:06:30.530 --> 00:06:31.990
But when you calculate a p-value,

102
00:06:31.990 --> 00:06:35.510
all you can do is make a statement
about the probability of the data.

103
00:06:37.110 --> 00:06:39.640
Now, if you make this mistake,
you're in good company.

104
00:06:39.640 --> 00:06:44.160
Let's take a look at this example from
quantum physics, where a physicist talks

105
00:06:44.160 --> 00:06:49.180
about the probability of observing
a certain spin between quantum particles.

106
00:06:49.180 --> 00:06:53.320
So, this is a study where they
measured the spin in a particle levels

107
00:06:53.320 --> 00:06:56.460
floating around somewhere in Delft,
and another one that was floating

108
00:06:56.460 --> 00:06:59.430
around somewhere in Amsterdam,
in the Netherlands, and

109
00:06:59.430 --> 00:07:03.780
these two particles spin together,
they have some sort of relationship.

110
00:07:03.780 --> 00:07:05.990
And this relationship, based on the data,

111
00:07:05.990 --> 00:07:10.334
was statistically significant
with a p-value of 0.04.

112
00:07:11.896 --> 00:07:16.080
Now, some physicist is interviewed
about this finding, and this physicist

113
00:07:16.080 --> 00:07:21.910
concludes, in other words, there is
a 96% probability they won the race.

114
00:07:23.370 --> 00:07:27.700
So, this person is making a mistake
here because, with won the race,

115
00:07:27.700 --> 00:07:32.980
this person means there's a 96%
probability that this theory is correct.

116
00:07:32.980 --> 00:07:34.910
But this is a statement about a theory.

117
00:07:34.910 --> 00:07:37.890
It's not a statement about
the data that you have observed.

118
00:07:37.890 --> 00:07:40.812
So it's comforting, maybe,
that a quantum physicist,

119
00:07:40.812 --> 00:07:43.616
which sounds like you're
supposed to be really smart,

120
00:07:43.616 --> 00:07:46.737
also makes this misinterpretation
of what a p-value means.

121
00:07:48.258 --> 00:07:53.408
After you have observed a p-value
that's smaller than 0.05,

122
00:07:53.408 --> 00:07:57.669
for example,
an effect is not 95% likely to be true.

123
00:07:57.669 --> 00:08:00.348
Think about pre-cognition research.

124
00:08:00.348 --> 00:08:03.330
Let's say that I present
one study to you where you

125
00:08:03.330 --> 00:08:07.120
find a statistically significant
effect of pre-cognition.

126
00:08:07.120 --> 00:08:13.860
After this, do you really think it's now
95% probable that pre-cognition exists?

127
00:08:13.860 --> 00:08:19.160
Probably not,
you cannot get the probability

128
00:08:19.160 --> 00:08:24.512
that the null hypothesis is true,
given the data from a p-value.

129
00:08:24.512 --> 00:08:29.860
If you look at the two statements below on
the screen, you see that the probability

130
00:08:29.860 --> 00:08:35.240
of the data, or more extreme data,
assuming the null hypothesis is true.

131
00:08:35.240 --> 00:08:39.090
It's not the same as
the probability of an hypothesis

132
00:08:39.090 --> 00:08:41.680
given some data that you have observed.

133
00:08:41.680 --> 00:08:43.558
This two probabilities can differ widely.

134
00:08:45.790 --> 00:08:49.127
If you want to know the probability
that the theory is true,

135
00:08:49.127 --> 00:08:51.770
you need to use Bayesian statistics.

136
00:08:51.770 --> 00:08:56.144
Bayesian statistics is the only
approach that will allow you to make

137
00:08:56.144 --> 00:08:59.988
statements about the probability
that the theory is true.

138
00:08:59.988 --> 00:09:06.004
What happens if you do a study and
your p-value is larger than 0.05?

139
00:09:06.004 --> 00:09:10.332
Well first of course, you spend a lot of
time and effort collecting this data, and

140
00:09:10.332 --> 00:09:14.070
maybe you hope to find
the statistically significant effect.

141
00:09:14.070 --> 00:09:17.120
So the first thing you do is cry a little,
you're a little bit depressed.

142
00:09:17.120 --> 00:09:20.530
That's okay, But after this how
should you interpret this data?

143
00:09:21.590 --> 00:09:24.875
Well, all that we know when
the p-value is larger than

144
00:09:24.875 --> 00:09:29.500
0.05 is that the data we have observed
is not surprising, that's all.

145
00:09:31.620 --> 00:09:34.810
It doesn't mean that
there is no true effect.

146
00:09:34.810 --> 00:09:36.970
There might very well be in effect but

147
00:09:36.970 --> 00:09:42.080
you just didn't have enough participants
in your study to detect this effect.

148
00:09:42.080 --> 00:09:48.350
Remember that you need large samples
to statistically detect a small effect.

149
00:09:48.350 --> 00:09:51.440
So just because your
p-value is larger than 0.05

150
00:09:51.440 --> 00:09:54.360
doesn't allow you to conclude
that there is no effect.

151
00:09:54.360 --> 00:09:57.150
There might be very small effect,
you don't know.

152
00:09:59.340 --> 00:10:04.160
Personally, I try to think of
a p-value larger than 0.05 as mu,

153
00:10:04.160 --> 00:10:06.830
which is a concept from Zen Buddhism.

154
00:10:08.420 --> 00:10:12.020
In Zen Buddhism, there is a famous
saying that goes like this.

155
00:10:12.020 --> 00:10:18.140
A monk asked a Chinese Zen master,
does a dog have a Buddha-nature or not?

156
00:10:18.140 --> 00:10:19.630
So you might expect a yes or

157
00:10:19.630 --> 00:10:24.500
no answer here because that's also how
the question is phrased yes or no.

158
00:10:24.500 --> 00:10:29.670
But instead the Zen master answered mu,
which basically means I'm on

159
00:10:29.670 --> 00:10:33.940
asking the question it's negating
the question that's asked.

160
00:10:33.940 --> 00:10:37.432
Whenever you find a p-value
that's larger than 0.05,

161
00:10:37.432 --> 00:10:41.600
you might feel the tendency to say so
is there an effect or not?

162
00:10:41.600 --> 00:10:46.490
But whenever the p-value is larger than
0.05, you can't answer this question.

163
00:10:46.490 --> 00:10:51.230
So you should just answer mu.

164
00:10:51.230 --> 00:10:53.300
So how do you use p-values correctly?

165
00:10:54.330 --> 00:10:58.060
The first thing to understand
is that p-values can be use

166
00:10:58.060 --> 00:11:02.010
as a rule to guide
behavior in the long run.

167
00:11:02.010 --> 00:11:07.310
You can calculate them for every single
study, but they only work in the long run.

168
00:11:07.310 --> 00:11:09.920
Let's take a look how.

169
00:11:09.920 --> 00:11:14.960
If you use the decision rule whenever the
p-value is smaller than the alpha level,

170
00:11:14.960 --> 00:11:19.597
so this is your type one error rate,
which is often set to 0.05,

171
00:11:19.597 --> 00:11:24.350
you can act as if the data is not noise.

172
00:11:24.350 --> 00:11:27.440
Now this word act is very important.

173
00:11:27.440 --> 00:11:32.050
It's independent of what you believe is
true, but all that you know is, if you use

174
00:11:32.050 --> 00:11:36.880
this decision rule in the long run,
you won't say that there is something,

175
00:11:36.880 --> 00:11:40.566
when there is nothing,
more than 5% of the time.

176
00:11:42.060 --> 00:11:47.420
Alternatively, when the p-value is larger
than the alpha you can remain uncertain or

177
00:11:47.420 --> 00:11:50.620
act as if the data is just noise.

178
00:11:50.620 --> 00:11:54.050
So these are rules that you
follow in the long run.

179
00:11:54.050 --> 00:11:59.360
When you act as if there is an effect
whenever the p-value is smaller than 0.05,

180
00:11:59.360 --> 00:12:06.910
in the long run you won't be
wrong more than 5% of the time.

181
00:12:06.910 --> 00:12:12.340
Now this is an interpretation of p-values
as proposed by name and it's often used.

182
00:12:12.340 --> 00:12:16.440
Let's take the discovery of
the Higgs boson as an example.

183
00:12:16.440 --> 00:12:20.522
If you're a remember, during the press
conference about the Higgs boson,

184
00:12:20.522 --> 00:12:25.170
researchers were talking about whether
the 5 sigma threshold was passed.

185
00:12:25.170 --> 00:12:31.320
And 5 sigma is used as a threshold to
declare something a discovery in physics.

186
00:12:31.320 --> 00:12:38.670
Now 5 sigma is basically
a p-value smaller than 0.0000003.

187
00:12:38.670 --> 00:12:44.110
So based on this idea,
we can act as if the Higgs boson is true.

188
00:12:45.470 --> 00:12:46.040
Every now and

189
00:12:46.040 --> 00:12:50.650
then of course we'll be wrong with
such a high threshold for an error.

190
00:12:50.650 --> 00:12:55.310
We'll only be wrong in one of many
billions of parallel universes.

191
00:12:55.310 --> 00:12:59.050
So there's one parallel universe
where people spend the time and

192
00:12:59.050 --> 00:13:03.640
effort to build a large Hadron Collider
to detect the Higgs boson and

193
00:13:03.640 --> 00:13:05.970
they declared it was
a statistically significance.

194
00:13:05.970 --> 00:13:09.430
So it was they were actually wrong but

195
00:13:09.430 --> 00:13:12.490
with such a high threshold this
of course rarely happens and

196
00:13:12.490 --> 00:13:16.240
we can be pretty safe that there is a
Higgs boson and we didn't make a mistake.

197
00:13:18.560 --> 00:13:23.695
When you interpret p-values and
you want to write something about what you

198
00:13:23.695 --> 00:13:29.740
found you should not write, we found a
p-value smaller than 0.05, so our theory.

199
00:13:29.740 --> 00:13:34.559
Because if you do this, you're
making a statement about this theory

200
00:13:34.559 --> 00:13:37.891
based on a p-value and
you shouldn't do this.

201
00:13:37.891 --> 00:13:42.493
The correct way to discuss a p-value
smaller than 0.05 is to say we

202
00:13:42.493 --> 00:13:46.242
found the p-value smaller than 0.05,
so our data.

203
00:13:46.242 --> 00:13:50.974
You make a statement about the data
because that's what the p-value

204
00:13:50.974 --> 00:13:52.310
relates to.

205
00:13:52.310 --> 00:13:53.940
You might say something like, so

206
00:13:53.940 --> 00:13:58.280
our data is in line with some
idea that you want to test.

207
00:14:01.150 --> 00:14:06.840
Whenever you found a known significant
result, a p-value larger than 0.05.

208
00:14:06.840 --> 00:14:10.680
You enter what's known as
a degenerative research line.

209
00:14:10.680 --> 00:14:13.350
You made a prediction but
it doesn't hold up.

210
00:14:13.350 --> 00:14:16.020
So you have something to explain.

211
00:14:16.020 --> 00:14:19.045
Now one explanation might
just be random variation.

212
00:14:19.045 --> 00:14:23.810
P-values vary and even if you have
examined a true effect, every now and

213
00:14:23.810 --> 00:14:26.660
then you'll observe
a non-significant result.

214
00:14:26.660 --> 00:14:30.120
So you might just say,
everything's fine, this happens.

215
00:14:30.120 --> 00:14:34.650
If I do another study that's exactly the
same, you'll see that it will pan out and

216
00:14:34.650 --> 00:14:36.550
my prediction will hold.

217
00:14:36.550 --> 00:14:37.930
Other times, you might need to say,

218
00:14:37.930 --> 00:14:41.950
well the effect that I predicted
might be smaller than I expected.

219
00:14:41.950 --> 00:14:44.070
So you do another study,
but it's larger and

220
00:14:44.070 --> 00:14:45.960
then you show that
the effect is really there.

221
00:14:47.500 --> 00:14:50.790
Nevertheless, whenever you
find a non-significant result,

222
00:14:50.790 --> 00:14:53.010
there is something to think about.

223
00:14:53.010 --> 00:14:54.980
You have to explain it in some way.

224
00:14:54.980 --> 00:14:58.480
One way might be, if you do a lot of
studies, every now and then you will find

225
00:14:58.480 --> 00:15:03.130
a non significant result, but then you
need a lot of studies to support this.

226
00:15:03.130 --> 00:15:06.950
Other times you might say, I have to do
the study in a slightly different way, and

227
00:15:06.950 --> 00:15:11.658
you can use this change in the paradigm
to develop a progressive research line.

228
00:15:11.658 --> 00:15:14.683
Remember that p-values vary so

229
00:15:14.683 --> 00:15:19.740
always think meta-analytically
about p-values.

230
00:15:19.740 --> 00:15:23.980
This is also recommended by the
statisticians who talked about p-values in

231
00:15:23.980 --> 00:15:25.280
the very beginning.

232
00:15:25.280 --> 00:15:29.080
For example,
this is a quote by Neyman and Pearson.

233
00:15:29.080 --> 00:15:32.850
Statistical tests should
be used with discretion and

234
00:15:32.850 --> 00:15:37.780
understanding, and not as instruments
which themselves give the final verdict.

235
00:15:38.860 --> 00:15:42.070
So if you fail a statistical
test that's only one thing

236
00:15:42.070 --> 00:15:45.412
that should go into your reasoning to
decide whether this is a true effect.

237
00:15:45.412 --> 00:15:48.601
Always think more about your study.

238
00:15:48.601 --> 00:15:53.358
P-value might be a starting points, but
you also want to look at effect sizes and

239
00:15:53.358 --> 00:15:55.490
other studies that have been done.

240
00:15:55.490 --> 00:15:59.677
Fisher similarly says
that a single p-value was

241
00:15:59.677 --> 00:16:03.259
not enough to declare some discovery on.

242
00:16:03.259 --> 00:16:08.197
He says, a phenomenon is experimentally
demonstrable when we know how

243
00:16:08.197 --> 00:16:11.982
to conduct an experiment which
will rarely fail to give

244
00:16:11.982 --> 00:16:14.881
us a statistically significant result.

245
00:16:14.881 --> 00:16:18.364
So we have to repeat
the experiment multiple times.

246
00:16:18.364 --> 00:16:23.738
He also says, no isolated experiment,
however significant in itself,

247
00:16:23.738 --> 00:16:29.382
can suffice for the experimental
demonstration of any natural phenomenon.

248
00:16:29.382 --> 00:16:32.874
So he's saying that we
should see a single p-value,

249
00:16:32.874 --> 00:16:36.756
maybe as an invitation to
explore this effect further, but

250
00:16:36.756 --> 00:16:40.887
it can never be enough to declare
something a scientific fact.

251
00:16:40.887 --> 00:16:43.267
So we always need to
do several studies and

252
00:16:43.267 --> 00:16:47.424
p-values can guide us in the long run
in which studies we might want to do.

253
00:16:49.537 --> 00:16:51.445
So, at the end of this lecture,

254
00:16:51.445 --> 00:16:56.340
let's take a look at the p-values that you
can expect when there is a true effect.

255
00:16:56.340 --> 00:17:00.554
And the p-values that you might
expect when there is no true effect.

256
00:17:00.554 --> 00:17:05.375
Now, I never really realized how
p-values are distributed across studies

257
00:17:05.375 --> 00:17:06.963
when you do a lot of them.

258
00:17:06.963 --> 00:17:09.590
And I think it's very important
to understand this for

259
00:17:09.590 --> 00:17:11.712
the correct interpretation of a p-value.

260
00:17:11.712 --> 00:17:13.755
So take a moment to think about this.

261
00:17:13.755 --> 00:17:17.749
What kind of p-values would you
expect when there is a true effect?

262
00:17:17.749 --> 00:17:22.637
What kind of p-values would you
expect when there is no effect?

263
00:17:22.637 --> 00:17:25.539
Let's take a look what really happens.

264
00:17:25.539 --> 00:17:27.580
When there is a true effect,

265
00:17:27.580 --> 00:17:32.099
the p-value distribution depends
on the statistical power.

266
00:17:32.099 --> 00:17:35.129
Let's take a look at
the visualization of this.

267
00:17:35.129 --> 00:17:40.638
In this graph, you see the p-values for
100,000 studies,

268
00:17:40.638 --> 00:17:44.707
where every study had
50% statistical power.

269
00:17:44.707 --> 00:17:49.521
This means that it's 50% probable
that we'll observe a p-value

270
00:17:49.521 --> 00:17:51.847
that's smaller than 0.05.

271
00:17:51.847 --> 00:17:56.649
If we look at the p-value distribution,
we indeed see that it's much more likely

272
00:17:56.649 --> 00:18:00.625
to observe small p-values,
than it is to observe high p-values.

273
00:18:00.625 --> 00:18:07.422
And if we look at the leftmost bar,
we see that indeed 50,000 of the 100,000

274
00:18:07.422 --> 00:18:12.966
simulated studies yield a p-value
that falls between 0 and 0.05.

275
00:18:12.966 --> 00:18:16.577
Now, we might want to increase
the statistical power a little bit.

276
00:18:16.577 --> 00:18:21.054
You see that with higher power
we have basically pushed more of

277
00:18:21.054 --> 00:18:25.632
the p-values below the significance
threshold of 0.05.

278
00:18:25.632 --> 00:18:28.926
Here we have 80,000 of the 100,000

279
00:18:28.926 --> 00:18:32.552
simulated studies that
yield a significant effect.

280
00:18:32.552 --> 00:18:35.677
If we increase the statistical
power even more, to 95%,

281
00:18:35.677 --> 00:18:38.681
we now see that most of
the p-values that we'll observe,

282
00:18:38.681 --> 00:18:42.629
given that there is a true effect,
will fall below the significance level.

283
00:18:44.661 --> 00:18:49.723
So which p-values can you
expect when there is no effect?

284
00:18:49.723 --> 00:18:52.301
I really never knew this myself.

285
00:18:52.301 --> 00:18:55.285
I thought that p-values might
be distributed in a way that,

286
00:18:55.285 --> 00:18:58.454
if there's no effect,
we'll see a lot of very high p-values.

287
00:18:58.454 --> 00:19:01.939
Or I thought that it's possible
that maybe they're distributed

288
00:19:01.939 --> 00:19:05.167
as sort of a normal distribution,
but instead it turns out,

289
00:19:05.167 --> 00:19:08.926
that when there is no effect,
p-values are uniformly distributed.

290
00:19:08.926 --> 00:19:11.608
Every p-value is equally likely.

291
00:19:11.608 --> 00:19:15.428
And it also makes a lot of
sense if you understand it.

292
00:19:15.428 --> 00:19:20.466
In this case, we have simulated 100,000
studies where there is no true effect.

293
00:19:20.466 --> 00:19:24.380
And you see that, no matter where
you look in the distribution,

294
00:19:24.380 --> 00:19:28.384
low p-values or high p-values,
they're all equally likely.

295
00:19:28.384 --> 00:19:31.175
Now this makes sense because in this way,

296
00:19:31.175 --> 00:19:36.281
when there is a uniform distribution
it means that 5% of the p-values that

297
00:19:36.281 --> 00:19:41.179
we observe when there is no effect,
fall below the 0.05 threshold.

298
00:19:41.179 --> 00:19:45.735
So when there's no effect, we have a 5%
probability of making a type one error of

299
00:19:45.735 --> 00:19:50.176
saying there is a significant effect
when there's actually nothing going on.

300
00:19:50.176 --> 00:19:55.134
So here you can see this small type
one error rate highlighted in red.

301
00:19:55.134 --> 00:19:58.419
So this is what it means
to make a type one error.

302
00:19:58.419 --> 00:20:02.796
The reason that it's 5% is because
there's a uniform p-value distribution.

303
00:20:02.796 --> 00:20:07.406
If you would increase your
alpha level to 0.10 there's

304
00:20:07.406 --> 00:20:11.840
still 10% of the p-values
that fall below 0.10.

305
00:20:11.840 --> 00:20:16.624
To conclude, it's important to understand
how to correctly interpret the p-value.

306
00:20:16.624 --> 00:20:21.790
Its use is often criticized because people
incorrectly interpret what p-values mean.

307
00:20:21.790 --> 00:20:25.889
And I hope that after this lecture,
you won't be one of them.

308
00:20:25.889 --> 00:20:30.100
[MUSIC]