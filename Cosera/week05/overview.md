Some researchers have proposed that we stop using p-values, and instead report confidence intervals. Reporting confidence intervals is good practice, because they tell you something about how accurately you have estimated an effect size. At the same time, confidence intervals are misinterpreted as well (they are confusing intervals)! In Lecture 5.1 and assignment 5.1 you will learn how to interpret confidence intervals correctly.

When you design a new study, you can do so to aim for a specific level of accuracy (or a specific width of the confidence interval). In Lecture 5.2, you will learn different ways to plan the sample size for an experiment, including power analysis.

Sometimes, before planning the sample size for a new study, you might want to check whether there is enough reason to assume there is a true effect. In Lecture 5.3, you will learn the logic behind p-curve analysis.

Can’t get enough? Some suggestions for additional reading:

Lecture 5.1

A very complete and accessible explanation of confidence intervals can be found in the two articles below:

Cumming, G., & Finch, S. (2001). A Primer on the Understanding, Use, and Calculation of Confidence Intervals that are Based on Central and Noncentral Distributions. Educational and Psychological Measurement, 61(4), 532–574. http://doi.org/10.1177/0013164401614002

Cumming, G., & Fidler, F. (2009). Confidence Intervals: Better Answers to Better Questions. Zeitschrift Für Psychologie / Journal of Psychology, 217(1), 15–26. http://doi.org/10.1027/0044-3409.217.1.15

Some criticisms on Frequentist confidence intervals from a Bayesian perspective can be found in:

Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123.

Lecture 5.2

An excellent introduction to sample size planning is provided by Maxwell and colleagues:

Maxwell, S. E., Kelley, K., & Rausch, J. R. (2008). Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation. Annual Review of Psychology, 59(1), 537–563. http://doi.org/10.1146/annurev.psych.59.103006.093735

To learn more about power and power analysis, the go-to book is Cohen:

Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed). Hillsdale, N.J: L. Erlbaum Associates.

If you start to use G*power for sample size planning based on power analysis, read:

Faul, F., Erdfelder, E., Lang, A.-G., & Buchner, A. (2007). G* Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods, 39(2), 175–191.

Lecture 5.3

If you want to learn about using p-curve analysis in more detail, read the article introducing the technique. Definitely read it carefully before performing and interpreting your first p-curve analysis.

Simonsohn, U., Nelson, L. D., & Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimental Psychology: General, 143(2), 534.

A highly related statistical technique, p-uniform, is described here:

van Assen, M. A. L. M., van Aert, R. C. M., & Wicherts, J. M. (2015). Meta-analysis using effect size distributions of only statistically significant studies. Psychological Methods, 20(3), 293–309. http://doi.org/10.1037/met0000025
