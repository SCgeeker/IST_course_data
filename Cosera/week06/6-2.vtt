WEBVTT

1
00:00:00.000 --> 00:00:09.661
[MUSIC]
虛無為假

2
00:00:09.661 --> 00:00:13.600
In this lecture we'll talk about which hypothesis you might want to test.
這一講要談科學研究測試的假設

3
00:00:13.600 --> 00:00:17.110
In science, we often rely on null hypothesis significance testing, but
本課程談的科學研究依賴虛無假設檢定

4
00:00:17.110 --> 00:00:20.510
there are also some people who say that testing the null is very boring,
不過也有人認為這種方法很沒意義

5
00:00:20.510 --> 00:00:23.090
because the null is always false.
因為虛無代表不可能為真的事情

6
00:00:23.090 --> 00:00:28.210
Is this criticism valid, and if so, which hypothesis might we want to test instead?
如果這樣的質疑有效，所有研究到底要檢定什麼假設

7
00:00:28.210 --> 00:00:28.780
Let's take a look.
讓我們好好談一談

8
00:00:30.300 --> 00:00:34.570
In science, we very often use a null-hypothesis significance test.
許多科學研究常使用虛無假設檢定

9
00:00:34.570 --> 00:00:39.690
Is the data we have observed surprising, assuming that the null-hypothesis is true?
如果發現是顯著的，能不能說虛無假設為真？

10
00:00:39.690 --> 00:00:41.520
This practice is also often criticized.
許多學者批評這樣的操作

11
00:00:42.660 --> 00:00:47.890
One of the critics of this is Cohen who says, the null hypothesis,
其中一位批評者就是Cohen

12
00:00:47.890 --> 00:00:51.340
taken literally, is always false in the real world.
他說虛無假設就字面上的意思
是現實中不可能存在之事

13
00:00:52.650 --> 00:00:58.010
So if the null is always false, what's the big deal about rejecting it?
如果虛無的事物不會存在
何必要大費周章地拒絕它？

14
00:00:58.010 --> 00:00:59.280
So is this really true?
這樣就會讓發現變成真實嗎？

15
00:00:59.280 --> 00:01:01.459
Is the null hypothesis always false?
虛無假設一定是不存在的嗎？

16
00:01:02.610 --> 00:01:07.220
Well, not really, sometimes with very large sample sizes,
其實不見得，如果有相當大的樣本數

17
00:01:07.220 --> 00:01:10.780
some effects are pretty darn close to zero.
有的效果會變得相當接近0

18
00:01:10.780 --> 00:01:14.110
We can take a look in the many labs data set.
我拿Many Labs專案的公開資料說明

19
00:01:14.110 --> 00:01:18.540
Many labs project was a big replication study where 36 different
這項專案是36組實驗團隊合作

20
00:01:18.540 --> 00:01:23.200
laboratories all replicated the same set of studies.
嘗試重現14項實驗結果

21
00:01:23.200 --> 00:01:25.212
So here every line is a different study.
圖中每一條線代表一項實驗

22
00:01:25.212 --> 00:01:30.551
And if we look at the bottom, we see that at least two of these studies with more
最下面的兩項研究都有超過5000位參與者資料

23
00:01:30.551 --> 00:01:36.680
than 5,000 participants yield an effect size that is indistinguishable from 0.
再現結果的效果量幾乎等於0

24
00:01:36.680 --> 00:01:39.710
Now the question is whether if we would continue to an infinite
進一步可以問如果持續收集無限大的資料
會不會看到統計顯著的結果

25
00:01:39.710 --> 00:01:43.920
number of observations there will be a statistically significant effect.
進一步可以問如果持續收集無限大的資料
會不會看到統計顯著的結果

26
00:01:43.920 --> 00:01:45.330
We don't really know, but
老實說沒人知道

27
00:01:45.330 --> 00:01:48.660
it seems unlikely that this really matters in practice most of the time.
沒有一項研究的主持人會把這樣的問題當真

28
00:01:51.020 --> 00:01:53.760
It's important to distinguish between one situation
更重要的是區分合理的虛無假設

29
00:01:53.760 --> 00:01:56.720
where the null is a very reasonable hypothesis and
更重要的是區分合理的虛無假設

30
00:01:56.720 --> 00:02:01.180
a situation where the null is not a very reasonable hypothesis.
與不合理的虛無假設

31
00:02:01.180 --> 00:02:06.650
If we use random assignment to conditions and we successfully accomplish this,
使用隨機分派執行樣本分組時

32
00:02:06.650 --> 00:02:10.810
then there's no reason to assume that there is a difference between two groups,
許多研究的預設是分組間沒有差異

33
00:02:10.810 --> 00:02:15.360
unless the manipulation that we use in our experiment actually has an effect.
除非分組的操作能導致真正的效果

34
00:02:15.360 --> 00:02:17.990
And if it's possible that the manipulation has no effect and
如果操作有可能是無效果

35
00:02:17.990 --> 00:02:21.410
this is a question you're interested in, then we can test the null.
檢定這樣的"虛無"就能回答研究者的問題

36
00:02:22.670 --> 00:02:26.740
However, we also sometimes test for measured variables.
但是有時候使用統計檢定的目的是測量變項

37
00:02:26.740 --> 00:02:29.660
An example of a measured variable is gender.
一個耳熟能詳的例子是性別

38
00:02:30.730 --> 00:02:34.810
People often enter the lab with a specific gender.
多數研究的參與者屬於特定性別

39
00:02:34.810 --> 00:02:36.800
They have the same gender throughout their lives,
因為大多數人的生命裡維持一種性別

40
00:02:36.800 --> 00:02:38.840
so it's not something that you can easily change.
不可能進行人為改變

41
00:02:40.240 --> 00:02:43.280
If you want to look at differences between men and women, for
想要比較男女生的差異

42
00:02:43.280 --> 00:02:46.140
example, then you cannot directly manipulate this.
是無法用隨機分派的

43
00:02:46.140 --> 00:02:48.980
You can only measure this variable and look at the differences.
只能由收集到的資料測量性別差異

44
00:02:50.020 --> 00:02:52.020
Now let's see why this matters.
變項能否操作有何值得注意之處

45
00:02:52.020 --> 00:02:55.610
We can compare the effect of random assignment and
可以從比較Many Labs專案資料裡隨機分派變項

46
00:02:55.610 --> 00:02:58.320
measured variables in the many labs data set.
與純測量變項的效果差異得知

47
00:02:59.550 --> 00:03:02.960
Let's take a look at one manipulated condition.
就拿定錨與性別為例

48
00:03:02.960 --> 00:03:07.430
In this case, we look at the anchoring condition people are randomly assigned.
定錨是隨機分派的操作

49
00:03:07.430 --> 00:03:12.850
Now in anchoring, people receive either a high or a low number as a manipulation.
定錨的操作是分派大小數字給參與者 

50
00:03:12.850 --> 00:03:13.560
Then after that,
一段時間之後

51
00:03:13.560 --> 00:03:16.730
they all mak the same estimate about something they're uncertain about.
估計某個不確定狀況的數值

52
00:03:18.010 --> 00:03:22.350
And what the literature shows is that this estimate is influenced by the height
文獻數據顯示定錨數字大小會影響估計的答案

53
00:03:22.350 --> 00:03:23.790
of the anchor.
文獻數據顯示定錨數字大小會影響估計的答案

54
00:03:23.790 --> 00:03:25.670
If they first get a very high number,
分派到大數字的參與者 

55
00:03:25.670 --> 00:03:29.250
their judgment under uncertainty is increased a little bit.
傾向給出高估的數字

56
00:03:29.250 --> 00:03:32.700
And if they get a very low number, then their estimate is slightly lower.
分派到小數字的參與者的估計則偏低

57
00:03:34.070 --> 00:03:37.040
Now, we can take a look at whether being assigned to the high
透過資料分析可以了解

58
00:03:37.040 --> 00:03:39.560
anchoring condition or the low anchoring condition
高定錨參與者的表現有沒有不同於
低定錨參與者

59
00:03:39.560 --> 00:03:43.380
has an effect on any of the other tests that participants did.
高定錨參與者的表現有沒有不同於
低定錨參與者

60
00:03:43.380 --> 00:03:44.900
So they did a lot of tests.
為此兩組參與者做了很多測試

61
00:03:44.900 --> 00:03:48.740
I'll look at ten different outcomes and see whether the random assignment to
我拿其中十種測試的資料做分析

62
00:03:48.740 --> 00:03:53.240
the anchoring condition has an effect on any of these other dependent variables.
看看定錨有沒有在其他依變項發生效果

63
00:03:54.460 --> 00:03:57.150
We can also take a look at whether there are gender effects.
像是比較性別在這些測試的表現

64
00:03:59.300 --> 00:04:03.590
If we do this, we see that the anchoring condition only has an effect on one
分析之後發現定錨的操作只在預期有效的測試結果
造成差異

65
00:04:03.590 --> 00:04:08.890
specific dependent variable, the anchoring effect that it's intended to influence.
分析之後發現定錨的操作只在預期有效的測試結果
造成差異

66
00:04:10.230 --> 00:04:13.400
However, if we look at gender effects in this dataset,
再看測試資料的性別差異

67
00:04:13.400 --> 00:04:18.970
we see that 7 out of the 10 dependent variables here all show a gender effect.
會發現其中七種測試有性別差異

68
00:04:18.970 --> 00:04:20.980
That's a very high number.
這數目超出預期

69
00:04:20.980 --> 00:04:23.180
So why is this the case?
為何有此結果

70
00:04:23.180 --> 00:04:24.340
We don't know.
沒人曉得

71
00:04:24.340 --> 00:04:27.050
There are probably things that vary with gender
也許資料中有其他變項和性別共變
導致測試結果的差異

72
00:04:27.050 --> 00:04:30.950
that also influence the other dependent variables that we're measuring.
也許資料中有其他變項和性別共變
導致測試結果的差異

73
00:04:30.950 --> 00:04:33.563
Now in all these studies there are also manipulations, and
專案裡的所有研究都有操弄

74
00:04:33.563 --> 00:04:35.451
these were the main interests in the test.
是預期對測試有效果的變項

75
00:04:35.451 --> 00:04:39.860
But we see that gender effects are always present or very often present.
然而性別差異隨處可見

76
00:04:39.860 --> 00:04:41.630
So whenever we have a measured variable,
如果研究有純測量變項

77
00:04:41.630 --> 00:04:44.010
it might be less interesting to test the null.
效果是不是存在通常不是檢定重點

78
00:04:44.010 --> 00:04:46.210
Very often the null is not true.
虛無通常代表不存在之事

79
00:04:46.210 --> 00:04:48.240
It's not a very interesting thing to see.
也不是有興趣知道之事

80
00:04:50.380 --> 00:04:51.539
So why is this the case?
那要如何看待像性別差異的結果？

81
00:04:52.830 --> 00:04:55.910
There is systematic noise in your data.
這類結果通常是資料中的背景噪音

82
00:04:55.910 --> 00:04:58.641
Lykken and Meehl call this the crud factor.
Lykken與Meehl稱之為無意義因子

83
00:04:58.641 --> 00:05:02.982
As long as you measure enough observations, these systematic differences
只要資料夠多，這些因子都會呈現統計顯著結果

84
00:05:02.982 --> 00:05:08.590
that are present in your data will always yield a statistically significant result.
只要資料夠多，這些因子都會呈現統計顯著結果

85
00:05:08.590 --> 00:05:11.169
Now remember that in the many labs projects there were
因為Many Labs專案有5000多位參與者

86
00:05:11.169 --> 00:05:13.012
more than 5,000 participants.
因為Many Labs專案有5000多位參與者

87
00:05:13.012 --> 00:05:15.010
So this is a very large data set.
基本上就是巨量資料

88
00:05:15.010 --> 00:05:15.970
And these tiny,
這些細微的

89
00:05:15.970 --> 00:05:20.120
systematic noises will lead to differences on your dependent variable.
背景噪音自然會造成依變項的差異

90
00:05:20.120 --> 00:05:22.650
So these things are not completely interesting.
這些因子本來與研究者的問題無關

91
00:05:22.650 --> 00:05:26.230
They might be, but it's very difficult to pinpoint the origin of these effects.
找到差異源頭的可能性相當低

92
00:05:26.230 --> 00:05:29.650
It might be just some sort of noise you're not interested in.
較有可能是與重要資訊無關的噪音

93
00:05:29.650 --> 00:05:33.395
So whenever we can manipulate the factor, the null might be more interesting, but in
可操作變項的"虛無假設"是真正有興趣的

94
00:05:33.395 --> 00:05:37.200
these cases of measured variables, there's always the crud factor to keep in mind.
但是請記住純測量變項通常是無意義因子

95
00:05:40.010 --> 00:05:44.010
So we can conclude that in principle, all models are wrong, but
至此我們可以說“所有模型都是錯的”

96
00:05:44.010 --> 00:05:45.960
some models are useful.
“不過有些是有用的”

97
00:05:45.960 --> 00:05:48.695
This is a statement by George Box.
出自George Box的名言

98
00:05:48.695 --> 00:05:52.468
What he means is that you can have a model that can be a useful test.
意思是說任何研究必能找到做有意義檢定的模型

99
00:05:52.468 --> 00:05:57.980
After randomization it's possible, so when you can randomly assign people to
隨機化是讓模型有用的關鍵
只要隨機分派參與者到各種情況

100
00:05:57.980 --> 00:06:03.600
conditions, the null can be a useful and a true hypothesis that you're interested in.
“虛無”就有檢定有興趣的假設是否為真的用處

101
00:06:03.600 --> 00:06:06.362
But without randomization, the alternative,
反過來說，沒有隨機化

102
00:06:06.362 --> 00:06:09.806
saying that there is an effect is not a very bold prediction.
宣稱存在效果並非了不起的預測

103
00:06:09.806 --> 00:06:11.540
There very often is an effect.
非隨機化的效果相當常見

104
00:06:14.000 --> 00:06:15.330
If the null is rarely true,
如果虛無有一點存在的可能性

105
00:06:15.330 --> 00:06:19.100
then refuting the null says very little about the truth of a theory.
拒絕虛無假設無助於分辨理論的真假

106
00:06:19.100 --> 00:06:21.010
You have to make a better prediction.
先需要一個好的預測

107
00:06:21.010 --> 00:06:25.140
You have to do something more than just testing the null hypothesis.
檢定必須有對立於虛無假設的預測才有意義

108
00:06:25.140 --> 00:06:30.430
The null hypothesis itself is what we know as a very weak hypothesis.
虛無假設是相對較弱的預測

109
00:06:30.430 --> 00:06:31.380
Let's give an example.
來看這個例子

110
00:06:32.380 --> 00:06:36.860
If I predict that it will rain next year in April,
今天我預測明年四月會下雨

111
00:06:36.860 --> 00:06:39.370
then that's not a very strong hypothesis.
這並非夠強的預測

112
00:06:39.370 --> 00:06:41.390
It's very easy to say that this is true.
只要四月任何一天有下雨

113
00:06:41.390 --> 00:06:42.046
This is going to happen.
這個預測都可以成真

114
00:06:42.046 --> 00:06:46.602
And you won't be impressed if I make this prediction and it turns out to be true.
我的預測成真的話也沒有人覺得神奇

115
00:06:46.602 --> 00:06:50.790
You can also make a strong prediction, have a strong hypothesis.
因此需要一個更強的預測及假設

116
00:06:50.790 --> 00:06:55.570
If I say that it will rain 7 millimeters on April 2nd next year and
現在我說明年四月二號會下7公釐的雨量

117
00:06:55.570 --> 00:06:58.080
it turns out that this prediction is true,
要證明預測為真

118
00:06:58.080 --> 00:07:00.450
now that will get me a job as a very good weatherman.
需要一位優秀的氣象專家評斷

119
00:07:02.620 --> 00:07:06.940
So null hypothesis significance testing rejects the null compared to
虛無假設顯著檢定的功用是剔除相對於
任何對立假設或預測的虛無假設

120
00:07:06.940 --> 00:07:09.930
any alternative, any other prediction goals.
虛無假設顯著檢定的功用是剔除相對於
任何對立假設或預測的虛無假設

121
00:07:09.930 --> 00:07:12.300
And that's not very exciting in some situations.
這種功用在某些情況並無太大幫助

122
00:07:12.300 --> 00:07:13.530
In these situations,
拿天氣預測為例，通常是定量的預測

123
00:07:13.530 --> 00:07:16.522
just as with the weather, you want to make a point prediction.
拿天氣預測為例，通常是定量的預測

124
00:07:16.522 --> 00:07:18.594
You want to say, this is what I predict.
你可以說“這就是我的預測”

125
00:07:18.594 --> 00:07:22.640
I just don't predict an effect, but I can predict with my theory,
“我不只預測這樣的結果，而是根據我的理論”

126
00:07:22.640 --> 00:07:25.830
which is pretty good, an effect of a specific size.
“推測會有這樣的雨量”

127
00:07:25.830 --> 00:07:28.469
And if you can accomplish this, that's much more impressive.
如果真能如此，才算是值得注意的研究

128
00:07:30.210 --> 00:07:35.510
So confirming strong hypotheses gives a theory greater verisimilitude,
驗證強假設可增加理論的“似真度”

129
00:07:35.510 --> 00:07:40.560
and that's a very difficult word for something that's akin to truth likeness.
這個不常見的詞意指逼近事實的程度

130
00:07:40.560 --> 00:07:42.383
It gets you money in the bank.
理論與資料的關係

131
00:07:42.383 --> 00:07:47.644
This is a finding that will increase your confidence in the theory,
好比把錢存在銀行
存越多信用額度越高

132
00:07:47.644 --> 00:07:49.779
and that's what you want.
好比把錢存在銀行
存越多信用額度越高

133
00:07:49.779 --> 00:07:52.030
Now let's play a small game.
讓我們玩個小遊戲

134
00:07:52.030 --> 00:07:56.020
I'll ask you what the rule is underlying the numbers that are presented
請猜猜有什麼規則讓這些數字秀出來

135
00:07:56.020 --> 00:07:57.140
on the screen.
請猜猜有什麼潛規則讓這些數字秀出來

136
00:07:57.140 --> 00:08:00.095
You see the numbers 2, 4, and 6.
現在有2,4,6

137
00:08:00.095 --> 00:08:04.065
You can test the rule by naming any other number that you think will follow
你可以叫出任何一個可能是第四個的數字
來測試潛規則

138
00:08:04.065 --> 00:08:04.660
the rule.
你可以叫出任何一個可能是第四個的數字
來測試潛規則

139
00:08:06.540 --> 00:08:09.820
Come up with any number you want, and I will say, yes,
你的回答符合規則的話，我會說“是”

140
00:08:09.820 --> 00:08:12.320
it follows the rule or no, it will not the follow the rule.
不符合規則的話，我會說“否”

141
00:08:14.000 --> 00:08:16.480
Take a moment to think of any number you want.
暫停一下想個數字

142
00:08:16.480 --> 00:08:17.880
Which number would you like to test?
你的回答是什麼呢？

143
00:08:19.490 --> 00:08:22.559
Let's say that you come up with the number 8.
假如你的回答是8

144
00:08:22.559 --> 00:08:23.701
This makes sense, right?
似乎是有規則的，對吧？

145
00:08:23.701 --> 00:08:27.793
You see 2 and you add 2, you get 4, you add 2, you get 6, so
因為2加2是4，再加2是6

146
00:08:27.793 --> 00:08:30.460
maybe this is the rule, just adding 2.
所以加2可能就是潛規則

147
00:08:30.460 --> 00:08:34.400
So if you would test 8 I can say yes, that's a valid number.
我若回答8是正確的，
那就是合乎規則的有效答案

148
00:08:34.400 --> 00:08:35.200
It follows the rule.
我若回答8是正確的，
那就是合乎規則的有效答案

149
00:08:36.800 --> 00:08:37.960
You might have a different theory.
你也可能有另一種理論

150
00:08:37.960 --> 00:08:42.740
You might say, well, maybe it's 4 plus the number that comes before it.
認為中間的4是代表2與6的差異
所以第四個可能是10

151
00:08:42.740 --> 00:08:48.440
So then we have 4 and 2 and 6, and then the next number might be 10.
認為中間的4是代表2與6的差異
所以第四個可能是10

152
00:08:48.440 --> 00:08:51.040
So, if you want to test the number 10, perfectly fine.
10也是一個很好的答案

153
00:08:51.040 --> 00:08:52.480
Yes, it also follows the same rule.
這個數字也顯示一種規則

154
00:08:53.720 --> 00:08:55.470
But you have not learned a lot.
但你無法因此獲得有用的資訊

155
00:08:55.470 --> 00:08:57.290
Is this really the underlying rule?
潛規則真是如此嗎？

156
00:08:57.290 --> 00:08:59.720
What would happen if you would say 7?
如果回答7又是怎樣呢？

157
00:08:59.720 --> 00:09:02.870
Now, that's a very interesting question, because in this case,
這些回答點出一個很有趣的問題

158
00:09:02.870 --> 00:09:05.980
you're not trying to confirm the rule that you have in your mind.
你做回答並不是要確認設想的潛規則

159
00:09:05.980 --> 00:09:09.319
You're trying to disconfirm, falsify your prediction.
而是要推翻否證心裡的預測

160
00:09:10.490 --> 00:09:15.670
If I say 7, or if you say 7, then I'd say yes, that's also following
如果7也得到正確的回應

161
00:09:15.670 --> 00:09:20.610
the same rule because in this case, the rule might be increasing numbers.
表示只有第四個數字比前面大都符合潛規則

162
00:09:20.610 --> 00:09:22.889
As long as the next number is an increasing number,
只要之後的數字都比前面大

163
00:09:22.889 --> 00:09:24.323
it follows the rule that I have.
都符合我設定的潛規則

164
00:09:24.323 --> 00:09:27.714
And you would never discover this if you just tried to confirm the idea that you
但若你只想測試心中的規則
你永遠不會發現

165
00:09:27.714 --> 00:09:28.560
have in your head.
但若你只想測試心中的規則
你永遠不會發現

166
00:09:31.040 --> 00:09:34.630
So whenever we do a study and we try to confirm our predictions,
同樣地為了確認預測而做的研究

167
00:09:34.630 --> 00:09:39.370
then this confirmation bias can be a systematic error in inductive reasoning.
也會因"確證性偏誤"導致歸納的系統性誤差

168
00:09:39.370 --> 00:09:42.640
You cannot learn whether your theory is actually true if you
如果只一心一意確證一種預測
將無法知道理論是否正確

169
00:09:42.640 --> 00:09:45.090
only set out to confirm your predictions.
如果只一心一意確證一種預測
將無法知道理論是否正確

170
00:09:46.630 --> 00:09:49.980
Instead, you should try to have stronger
所以應該以否證最強的預測為重點

171
00:09:49.980 --> 00:09:54.460
theoretical predictions where one of your predictions can be falsified.
所以應該以否證最強的預測為重點

172
00:09:54.460 --> 00:09:59.162
One way to do this is to set out test two competing predictions.
可行的方法是設定兩種相互競爭的假設

173
00:09:59.162 --> 00:10:03.510
Either the one hypothesis is true or the other, but they can't both be true.
其中一種假設可能為真
但絕不可能兩者都為真

174
00:10:03.510 --> 00:10:07.620
So when I find some data, I can say this is at least in line with the one theory
收集資料之後，要確認是否符合其中一種假設

175
00:10:07.620 --> 00:10:09.859
but is not in line with the other theory.
並且不符合另一種假設

176
00:10:10.880 --> 00:10:13.820
So this is already a more interesting comparison to make.
這樣的比較就能導致有意義的結論

177
00:10:13.820 --> 00:10:15.980
This is known as strong inference,
這就是所謂的強推論

178
00:10:15.980 --> 00:10:20.770
crucial experiments that can exclude one alternative hypothesis.
關鍵實驗通常能排除最不可能的假設

179
00:10:20.770 --> 00:10:23.590
And this is a very good way to have scientific progress.
因此促成科學良性進展

180
00:10:25.740 --> 00:10:29.012
According to Platt, who talks about strong inference,
Platt的這段話可提醒你如何設計
有效回答問題的研究

181
00:10:29.012 --> 00:10:32.982
you should always ask yourself the question when you design a study.
Platt的這段話可提醒你如何設計
有效回答問題的研究

182
00:10:32.982 --> 00:10:37.460
But what experiment could disprove your hypothesis?
“但是有什麼樣的實驗能否證假設？”

183
00:10:37.460 --> 00:10:39.810
That's the main thing you should set out to do.
請隨時拿這句話出來提醒自己

184
00:10:39.810 --> 00:10:43.560
Of course you might not feel like disproving all the nice ideas that you
當然這不是要你否證所有想到的點子

185
00:10:43.560 --> 00:10:47.110
have, but for science this is a very good thing to set out to do.
保持這樣的精神才是做科學研究的基本態度

186
00:10:48.680 --> 00:10:52.310
So we've seen that people sometimes criticize null hypothesis significance
因為虛無假設檢定的預測力不高

187
00:10:52.310 --> 00:10:54.610
testing because it's a very weak prediction.
而招來一些學者的批評

188
00:10:54.610 --> 00:10:57.470
Anything goes as long as the null is not true.
只要虛無非真，任何事都有可能發生

189
00:10:57.470 --> 00:10:59.567
And when you don't have random assignment,
若不是採用隨機分派進行研究

190
00:10:59.567 --> 00:11:03.389
even this idea of the null being true is not a very interesting hypothesis to make.
虛無假設就與真正想測試的想法無關

191
00:11:03.389 --> 00:11:06.796
So you should try to set out to make strong predictions,
好研究應當設定強預測

192
00:11:06.796 --> 00:11:10.218
test competing hypotheses whenever this is possible.
檢定任何相互競爭的假設

193
00:11:10.218 --> 00:11:14.589
[MUSIC]
影片結束
