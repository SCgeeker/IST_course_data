Although p-values, likelihood ratios, and Bayes factors are useful, very often you are interested in just estimating the size of an effect. This week, we will talk about effect sizes: How to interpret them, why they are important to report, and how to calculate them (with some hands-on experience in assignment 4.1).

Can’t get enough? Some suggestions for additional reading:

A very complete and detailed discussion of effect sizes can be found in:

Grissom, R. J., & Kim, J. J. (2012). Effect sizes for research: univariate and multivariate applications (2nd ed). New York: Routledge.

The book by Cumming (2013) mentioned earlier has excellent discussions on effect sizes (primarily focusing on Cohen’s d).

Cumming, G. (2013). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge.

I’ve written a practical primer on effect sizes, which you can find here:

Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4. http://doi.org/10.3389/fpsyg.2013.00863

Another practical introduction, focusing on contrasts, is provided by:

Rosnow, R. L., & Rosenthal, R. (2009). Effect Sizes: Why, When, and How to Use Them. Zeitschrift Für Psychologie / Journal of Psychology, 217(1), 6–14. http://doi.org/10.1027/0044-3409.217.1.6

An accessible book-level treatment of the topic can be found in:

Ellis, P. D. (2010). The essential guide to effect sizes: statistical power, meta-analysis, and the interpretation of research results. Cambridge ; New York: Cambridge University Press.
