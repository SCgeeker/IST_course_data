This week, we will dive into the topic of error control in much more detail. More specifically, we will look at how error rates can easily be inflated (but you typically don’t know by how much!). Often, it is possible to do all the analyses you want to do, while controlling your error rates. We will discuss how to do this in relation to ‘optional stopping’, which is performing a statistical test multiple times, as the data comes in, in assignment 3.2. In a Neyman-Pearson approach to using p-values, you should not only control the Type 1 error rate, but also the Type 2 error rate. The concept of statistical power (finding an effect, if it is really there) is explained in lecture 3.2. In assignment 3.2, you will see how low statistical power and inflated Type 1 error rates, together with publication bias, could lead to a scientific literature where most published findings are false. In lecture 3.3, you will learn the benefits of pre-registration to fix the Type 1 error rate in studies you perform. You will pre-register a small study in assignment 7.1. And check out the interview with Dan Simons on Registered Replication Reports to learn how pre-registration is used in psychology!

這個星期我們會深入討論控制錯誤率的方法。更具體地說，我們會看看錯誤率如何容易地膨脹（但你通常不知道膨脹多少！）。通常，您可以在控制錯誤率的同時進行數據分析。我們會在作業 3.2 中討論如何進行此操作並與“可選停止“進行比較。“可選停止“是對正搜集的數據作出多次分析。在使用p值的Neyman-Pearson方法中，不僅要控制型一的錯誤率，也要控制型二的。我們會在講演 3.2 中解释統計考驗力的概念（發現效果且效果真的存在）。在作業 3.2中，你將會看到低統計考驗力和膨脹的型一的錯誤率以及出版偏倚如何能影響科學文獻，導致大多數發表的研究结果都是假的結論。在講演 3.3 中，你將會學到預先註冊研究怎樣能修正型一的錯誤率。你會在作業 7.1中預先註冊一项小型研究。并查閱丹·西蒙斯對”登記複製報告“的訪問，了解如何在心理學中使用預先註冊！

Can’t get enough? Some suggestions for additional reading:

如果仍覺得不足，以下是一些建議的補充閱讀：

Lecture 3.1

講演 3.1

The quite recent, but already classic paper illustrating the problems of inflated Type 1 error rates is:

這是最近的一份文獻，但已成為經典的文章，討論型一的錯誤率膨脹的問題：

Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359–1366. http://doi.org/10.1177/0956797611417632

A good discussion of Type 1 error control is provided by:

一個對型一錯誤率控制很好的討論：

Rutherford, A. (2011). ANOVA and ANCOVA: a GLM approach (2nd ed). Hoboken, N.J: Wiley. Sections 3.6-3.10

If you want to use sequential analyses and benefit from their efficiency, without inflating type 1 error rates, I’ve written an accessible introduction:

如果您想使用順序分析並從其效率中獲益而不產生型一錯誤率，我寫了一個簡單的介紹：

Lakens, D. (2014). Performing high-powered studies efficiently with sequential analyses: Sequential analyses. European Journal of Social Psychology, 44(7), 701–710. http://doi.org/10.1002/ejsp.2023

A discussion of a way to directly control the false discovery rate can be found in:

關於直接控制虛假發現率(偽陽率)的方法的討論可以在這裡找到：

Benjamini, Y., & Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological), 289–300.

Lecture 3.2

講演 3.2

Cohen gives an accessible introduction to power, and why it is important, here:

科恩簡單的介紹統計考驗力介紹，以及這個概念的重要性：

Cohen, J. (1992). Statistical power analysis. Current Directions in Psychological Science, 1(3), 98–101.

A good article on weighing how bad a Type 1 error or a Type 2 error is is provided by Fiedler and colleagues:

一片由Fiedler及其同事提供的好文章，對型一或型二錯誤率作出比較，衡量兩者的糟糕性：

Fiedler, K., Kutzner, F., & Krueger, J. I. (2012). The Long Way From -Error Control to Validity Proper: Problems With a Short-Sighted False-Positive Debate. Perspectives on Psychological Science, 7(6), 661–669. http://doi.org/10.1177/1745691612462587

We discuss the importance of increasing the informational value of studies (either by improving the accuracy of estimates, or power analyses, and why large enough sample sizes are important) here:

我們討論增加研究的信息價值的重要性（通過提高估計的準確性或統計考驗力分析，及討論足夠大樣本量的重要性）：

Lakens, D., & Evers, E. R. K. (2014). Sailing From the Seas of Chaos Into the Corridor of Stability: Practical Recommendations to Increase the Informational Value of Studies. Perspectives on Psychological Science, 9(3), 278–292. http://doi.org/10.1177/1745691614528520

Assignment 3.2 is based on the two articles below:

作業3.2是基於以下兩篇文章：

Ioannidis, J. P. A. (2005). Why Most Published Research Findings Are False. PLoS Medicine, 2(8), e124. http://doi.org/10.1371/journal.pmed.0020124

Wacholder, S., Chanock, S., Garcia-Closas, M., El ghormli, L., & Rothman, N. (2004). Assessing the Probability That a Positive Report is False: An Approach for Molecular Epidemiology Studies. JNCI Journal of the National Cancer Institute, 96(6), 434–442. http://doi.org/10.1093/jnci/djh075

Lecture 3.3

講演 3.3

As solutions to the file-drawer problem, registered reports have been proposed. The three articles below introduce this novel format, and discuss how it can improve science.

登記報告是為文件抽屜問題所提出的其中一個解決方案 。以下三篇文章介紹了這種新穎的格式，並討論其如何改進科學。

Nosek, B. A., & Lakens, D. (2014). Registered reports: A method to increase the credibility of published results. Social Psychology, 45(3), 137–141. http://doi.org/10.1027/1864-9335/a000192

Chambers, C. D., Feredoes, E., Muthukumaraswamy, S. D., & Etchells, P. (2014). Instead of“ playing the game” it is time to change the rules: Registered Reports at AIMS Neuroscience and beyond. AIMS Neuroscience, 1(1), 4–17.

Simons, D. J., Holcombe, A. O., & Spellman, B. A. (2014). An introduction to registered replication reports at perspectives on psychological science. Perspectives on Psychological Science, 9(5), 552–555.

